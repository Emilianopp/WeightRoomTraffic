{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Specifying Chrome as Web Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimenting with the packages \n",
    "driver  = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 Data Retrival Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main functions used for web scrapping\n",
    "\n",
    "\n",
    "\n",
    "#Function list_maker \n",
    "#input column HTML column to convert into a python list\n",
    "#outputs python list of strings for the specified HTML column \n",
    "def list_maker(column):\n",
    "    make = []\n",
    "    for i in range(len(column)):\n",
    "        make.append(column[i].text)\n",
    "    return make\n",
    "\n",
    "#WebsSraper \n",
    "#inputs\n",
    "#Date specific date to get data from\n",
    "#driver specified selenium web driver to fetch data fram\n",
    "#will use the driver element to refresh the current webpage and find the table within the page. \n",
    "#It will go through each column and fetch data for each row\n",
    "#Then it will use lsit maker to make an appropriate list for every element stored in the table\n",
    "#Outputs a dictionary with all the column headers and their values for that specific date\n",
    "def WeatherScraper(Date, driver):\n",
    "    driver.get('https://www.wunderground.com/history/daily/ca/london/CYXU/date/{0}'.format(Date))\n",
    "    table = driver.find_element_by_xpath('//*[@id=\"inner-content\"]/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]/table')\n",
    "    headers = table.find_elements_by_xpath('//tr[2]/td')\n",
    "    rData = [] \n",
    "    col = np.arange(1,20)\n",
    "    for i in col:\n",
    "        col = table.find_elements_by_xpath(\"//tr/td[\"+str(i)+\"]\")\n",
    "        rData.append(col)\n",
    "    Time = list_maker(rData[0])\n",
    "    Temperature = list_maker(rData[1])\n",
    "    DewPoint =list_maker(rData[2])\n",
    "    Humidity = list_maker(rData[3])\n",
    "    Wind=list_maker(rData[4])\n",
    "    WindSpeed =list_maker(rData[5])\n",
    "    WindGust=list_maker(rData[6])\n",
    "    Pressure = list_maker(rData[7])\n",
    "    Precip = list_maker(rData[8])\n",
    "    Condition = list_maker(rData[9])\n",
    "\n",
    "    temp_clean = Temperature[22:]\n",
    "    time_clean = Time[22:]\n",
    "    dew_clean =  DewPoint[22:]\n",
    "    humidity_clean = Humidity[6:]\n",
    "    Date = {'Temperature':temp_clean,'Time' :time_clean,'Dew':dew_clean, 'Humidity' : humidity_clean, 'Wind' :Wind\n",
    "             ,'WindSpeed': WindSpeed,'WindGust' : WindGust,'Pressure' : Pressure,'Precip' : Precip, 'Condition' :Condition}\n",
    "    return Date\n",
    "\n",
    "\n",
    "#Function DateRangeCollector \n",
    "#inputs \n",
    "#start starting date\n",
    "#end ending date \n",
    "#file file name to save to\n",
    "#This is how we itterate through the webpage in full.\n",
    "#It will use function WebScrapper to collect the data for the given end and start range\n",
    "#it will then dump the returning dictionary into a pickel file to be available for retrieving later.\n",
    "#Trouble shooting is done within the function so if for some reason the data is unavailable when webscrapper is trying to retrieve it\n",
    "#this will dump the current dictionary into the file and print out a statement indicating what day the error occured in to \n",
    "#allow the proccess to be resumed in that day. \n",
    "#Outputs day_dict a dictionary of a ll the weather data\n",
    "\n",
    "def DateRangeCollector(start,end,file):\n",
    "    try:\n",
    "        f = open(f\"{file}\",\"wb\")\n",
    "        delta =  end - start\n",
    "        day_dict  = {}\n",
    "        driver  = webdriver.Chrome()\n",
    "        driver.implicitly_wait(3)\n",
    "        day = start\n",
    "        for i in range (delta.days + 1):\n",
    "            day = start + timedelta(i)\n",
    "            string_format = day.date().isoformat()\n",
    "            test = WeatherScraper(string_format,driver)\n",
    "            day_dict[string_format] =  test\n",
    "        pickle.dump(day_dict,f)\n",
    "        f.close()\n",
    "    except:\n",
    "        print('Error occured during this this date {0}'.format(string_format) )\n",
    "        pickle.dump(day_dict,f)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    return day_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4 Data Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function calls to collect the days \n",
    "start =datetime(2020,1,21)\n",
    "end =datetime(2020,4,1)\n",
    "dictionary_of_days = DateRangeCollector(start,end,'Weather2020_jan21')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
